{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: \n",
    "# Description: \n",
    "# Date Created: \n",
    "# Date Modified: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<ol> \n",
    "\n",
    "<li> Transformation, affine and non affine </li>  \n",
    "<li> Translations </li>    \n",
    "<li> Rotations </li> \n",
    "<li> Scaling, re-sizing and interpolations </li> \n",
    "<li> Image Pyramids </li> \n",
    "<li> Cropping </li> \n",
    "<li> Arithmetic Operations </li> \n",
    "<li> Bitwise Operations and Masking </li> \n",
    "<li> Convolutions & Blurring </li> \n",
    "<li> Sharpening </li> \n",
    "<li> Thresholding and Binarization </li> \n",
    "<li> Dilation, erosion, opening and closing </li> \n",
    "<li> Edge Detection & Image Gradients </li> \n",
    "<li> Perspective & Affine Transforms </li> \n",
    "       \n",
    "</ol> \n",
    "</p> \n",
    "\n",
    "<h3> Transformations </h3> \n",
    "<p> <b> Transformation </b> - are geometric distortions enacted upon an image. <br> \n",
    "We use transformations to correct distortions or perspective issues from arising from the point of view an image was captured. </p> \n",
    "\n",
    "<p> \n",
    "<b> Types: </b> \n",
    "<ul> \n",
    "<li> Affine: <p> Affine transformations include <b>Scaling</b>, <b>Rotation</b> and <b> Translation </b> \n",
    "\n",
    "</li>  <br> \n",
    "<li> Non-Affine: <p> Non-Affine or <b>Projective Transform</b> and also called <b>Homography.</b> It does not preserve parallelism, length, and angle. It does however preserve collinearity and incidence. <br> \n",
    "Non-Affine transformations are very common in computer vision. \n",
    "</p>  \n",
    "    \n",
    "    \n",
    "</li> \n",
    "</ul> \n",
    "</p> \n",
    "\n",
    "\n",
    "<h3> Translation </h3> \n",
    "<p> <b>Tx</b> represents the shift along the x-axis (horizontal) <br> \n",
    "    <b>Ty</b> represents the shift along the y-axis (vertical) <br> \n",
    "    \n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules \n",
    "import os \n",
    "import cv2 \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the image \n",
    "IMG_PATH = \"images/grande2.jpg\" \n",
    "\n",
    "# Reading the image into memory \n",
    "image = cv2.imread(IMG_PATH) \n",
    "\n",
    "# Resizing the image  \n",
    "image = cv2.resize(image, (600, 600))\n",
    "\n",
    "# Store the height and width of the image \n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Finding the quater_height, and quater_width of the image  \n",
    "quarter_height, quarter_width = height/4, width/4 \n",
    "\n",
    "# Finding half_height and half_width of the image  \n",
    "half_height, half_width = height/2, width/2 \n",
    "\n",
    "# Creating the translation matrix \n",
    "T = np.float32([[1, 0, quarter_width], [0, 1, quarter_height]])\n",
    "\n",
    "# Creating the translation matrix of half values \n",
    "T_half = np.float32([[1, 0, half_width], [0, 1, half_height]])\n",
    "\n",
    "# Transforming the image by using the warpAffine function and the matrix T \n",
    "img_translation = cv2.warpAffine(image, T, (width, height))\n",
    "\n",
    "# Transforming the image by using the warpAffine function for half_ \n",
    "img_half_translation = cv2.warpAffine(image, T_half, (width, height))\n",
    "\n",
    "# Displaying the image  \n",
    "cv2.imshow(\"Main Image\", image) \n",
    "cv2.imshow(\"Translated Image\", img_translation) \n",
    "cv2.imshow(\"Half Translated Image\", img_half_translation) \n",
    "\n",
    "# Waiting \n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   0. 150.]\n",
      " [  0.   1. 150.]] \n",
      "\n",
      "[[  1.   0. 300.]\n",
      " [  0.   1. 300.]]\n"
     ]
    }
   ],
   "source": [
    "# Viewing the matrices. \n",
    "print(T, \"\\n\") \n",
    "print(T_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Rotation </h3> \n",
    "\n",
    "<p> <b> OpenCV</b> allows you to scale and rotate at the same thing using the <b>cv2.getRotationMatrix2D</b> function. <br> \n",
    "    \n",
    "<b> cv2.getRotationMatrix2D(rotation_center_x, rotation_center_y, angle_of_rotation, scale) </b> \n",
    "    \n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules \n",
    "import os \n",
    "import cv2 \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the image \n",
    "IMG_PATH = \"images/grande2.jpg\" \n",
    "\n",
    "# Loading the image into memory \n",
    "image = cv2.imread(IMG_PATH) \n",
    "\n",
    "# Getting the height and width of the image  \n",
    "height, width = image.shape[:2] \n",
    "\n",
    "# Divide by two to rotate the image around its centre \n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), 287, 1) \n",
    "\n",
    "# Getting the rotated image \n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height)) \n",
    "\n",
    "# Displaying the image  \n",
    "cv2.imshow(\"Rotated Image\", rotated_image) \n",
    "\n",
    "# Waiting for a key pressed, then destroy all windows \n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Re-sizing, Scaling and Interpolation </h3> \n",
    "\n",
    "<p> What is interpolation ? <br> \n",
    "\n",
    "<b>Interpolation</b> is a method of constructing new data points within the range of a discrete set of known data points. <br> \n",
    "    \n",
    "<b> cv2.INTER_AREA </b> - Good for shrinking or down sampling <br> \n",
    "<b> cv2.INTER_NEAREST </b> - Fastest <br> \n",
    "<b> cv2.INTER_LINEAR </b> - Good for zooming or up sampling (default) <br> \n",
    "<b> cv2.INTER_CUBIC </b> - Better <br> \n",
    "<b> cv2.INTER_LANCZOS4 </b> - Best <br> \n",
    "\n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Re-sizing </h3> \n",
    "<p> Re-sizing is very easy using the cv2.resize function. it's arguments are <br> \n",
    "<b>cv2.resize(image, dsize(output_image_size), x_scale, y_scale, interpolation) </b> </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules \n",
    "import os \n",
    "import cv2 \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the image \n",
    "IMG_PATH = \"images/grande2.jpg\" \n",
    "\n",
    "# Loading the image into memory \n",
    "image = cv2.imread(IMG_PATH) \n",
    "\n",
    "# Resizing the image with 3/4 of it's original size \n",
    "image_scaled = cv2.resize(image, None, fx=0.3, fy=.3) \n",
    "cv2.imshow(\"Scaling - Linear Interpolation\", image_scaled) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Resizing the image with fx=2, and fy=2, this means doubling the size of the image  \n",
    "img_scaled = cv2.resize(image, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC) \n",
    "cv2.imshow(\"Scaling - Interpolation\", img_scaled) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# skewing the re-sizing by setting the exact dimensions \n",
    "img_scaled = cv2.resize(image, (100, 100), interpolation = cv2.INTER_AREA) \n",
    "cv2.imshow(\"Scaling - Skewed Size\", img_scaled) \n",
    "cv2.waitKey() \n",
    "\n",
    "# Destroying all windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cropping </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules \n",
    "import os \n",
    "import cv2 \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the image \n",
    "IMG_PATH = \"images/grande2.jpg\" \n",
    "\n",
    "# Loading the image into memory \n",
    "image = cv2.imread(IMG_PATH) \n",
    "\n",
    "# Resizing the image with 3/4 of it's original size \n",
    "image = cv2.resize(image, None, fx=.8, fy=.8) \n",
    "\n",
    "# Extracting the height and width of the image \n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Getting the starting pixels co-ordinates x1=start_column, y1=start_row \n",
    "start_row, start_col = 32, 117\n",
    "\n",
    "# Getting the ending pixel co-ordinates x2=end_column, y2=end_row  \n",
    "end_row, end_col = 204, 350\n",
    "\n",
    "# Simply use indexing to crop out the rectangle we desire \n",
    "cropped = image[start_row:end_row, start_col:end_col] \n",
    "\n",
    "# Displaying both images \n",
    "cv2.imshow(\"Grande\", image) \n",
    "cv2.imshow(\"Cropped Grande\", cropped) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "# print(height)\n",
    "\n",
    "# Getting the starting pixel co-ordinate (top left of cropping rectangle) \n",
    "# start_row, start_col = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Convolutions And Blurring </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules \n",
    "import os \n",
    "import cv2 \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Blurring Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the image \n",
    "IMG_PATH = \"images/grande2.jpg\" \n",
    "\n",
    "# Loading the image into memory \n",
    "image = cv2.imread(IMG_PATH) \n",
    "\n",
    "# Displaying the raw grande image \n",
    "cv2.imshow(\"Grande\", image) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Creating our 3 x 3 kernel ==> 9 \n",
    "kernel_3x3 = np.ones((3, 3), np.float32) / 9 \n",
    "\n",
    "# We use the cv2.filter2D to convolve the kernel with the image  \n",
    "blurred = cv2.filter2D(image, -1, kernel_3x3) \n",
    "cv2.imshow(\"3x3 Kernel Blurring\", blurred) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Creating our 7 x 7 kernel ==> 49 \n",
    "kernel_7x7 = np.ones((7, 7), np.float32) / 49 \n",
    "\n",
    "# We use the cv2.filter2D to convolve the kernel with the image \n",
    "blurred2 = cv2.filter2D(image, -1, kernel_7x7) \n",
    "cv2.imshow(\"7x7 Kernel Blurring\", blurred2)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Cleaning up \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Blurring Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the image \n",
    "IMG_PATH = \"images/grande1.jpg\"\n",
    "\n",
    "# Loading the image into memory \n",
    "image = cv2.imread(IMG_PATH) \n",
    "\n",
    "# Averaging done by convolving the image with a normalized box filter. \n",
    "# This takes the pixels under the box and replaces the central element \n",
    "# Box size needs to odd and positive \n",
    "blur = cv2.blur(image, (3, 3))\n",
    "cv2.imshow(\"Averaging\", blur) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Instead of box filter, gaussian kernel \n",
    "Gaussian = cv2.GaussianBlur(image, (7, 7), 0) \n",
    "cv2.imshow(\"Gaussian Blurring\", Gaussian) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Takes median of all the pixels under kernel area and central \n",
    "# Element is replaced with this media value \n",
    "median = cv2.medianBlur(image, 5) \n",
    "cv2.imshow(\"Median Blurring\", median) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Bilateral is very effective in noise removal while keeping edges sharp \n",
    "bilateral = cv2.bilateralFilter(image, 9, 75, 75) \n",
    "cv2.imshow(\"Bilateral Bluring\", bilateral) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image De-noising - Non-local means denoisng "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the image \n",
    "IMG_PATH = \"images/grande2.jpg\" \n",
    "\n",
    "# Reading the image \n",
    "image = cv2.imread(\"images/grande1.jpg\") \n",
    "image = cv2.resize(image, (300, 300), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Parameters, after None are - the filter strength \"h\" (5-10 is a good range) \n",
    "# Next is hForColorComponents, set as same value as h again. \n",
    "dst = cv2.fastNlMeansDenoisingColored(image, None, 6, 6, 7, 21) \n",
    "\n",
    "# Displaying the image \n",
    "cv2.imshow(\"Fast Means Denoising\", dst) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Destroying all windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> There are 4 variations of Non-Local Means Denoising: </h4> \n",
    "\n",
    "<ul> \n",
    "<li> cv2.fastNlMeansDenoising() - works with a single grayscale images </li> \n",
    "\n",
    "<li> cv2.fastNlMeansDenoisingColored() - works with a color image. </li> \n",
    "\n",
    "<li> cv2.fastNlMeansDenoisingMulti() - works with image sequence captured in short period of time (grayscale images) </li> \n",
    "    \n",
    "<li> cv2.fastNlMeansDenoisingColoredMulti() - same as above, but for color images. </li> \n",
    "    \n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
